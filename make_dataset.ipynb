{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T10:04:05.423080Z",
     "start_time": "2025-02-11T10:04:05.420174Z"
    }
   },
   "source": [
    "# Cell 1: Import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:53:47.809075Z",
     "start_time": "2025-02-11T10:53:47.803076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 1: Import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def clean_trump_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Reads Donald Trump's CSV, removes rows with links and pic.twitter,\n",
    "    keeps only one column, and adds a 'person' column.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Trump CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove rows containing links or pic.twitter\n",
    "    mask = ~(\n",
    "        df['content'].str.contains('http://|https://|pic\\.twitter', \n",
    "                                 regex=True, \n",
    "                                 na=False)\n",
    "    )\n",
    "    df = df[mask]\n",
    "    \n",
    "    # Keep only the 'content' column and add 'person' column\n",
    "    df = df[['content']].copy()\n",
    "    df['person'] = 'Donald Trump'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reorder_trump_columns(trump_df):\n",
    "    \"\"\"\n",
    "    Renames 'content' to 'text' and reorders columns to [person, text]\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): DataFrame with [content, person] columns\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with renamed and reordered columns [person, text]\n",
    "    \"\"\"\n",
    "    # Rename content to text\n",
    "    trump_df = trump_df.rename(columns={'content': 'text'})\n",
    "    \n",
    "    # Reorder columns\n",
    "    trump_df = trump_df[['person', 'text']]\n",
    "    \n",
    "    return trump_df"
   ],
   "id": "b203cfc5db764782",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:04:06.593517Z",
     "start_time": "2025-02-11T10:04:06.589512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Function to process directory of CSVs\n",
    "def combine_bob_ross_csv_files(directory_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a directory into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to directory containing CSV files\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame\n",
    "    \"\"\"\n",
    "    # List to store individual DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Iterate through all CSV files in the directory\n",
    "    for file in os.listdir(directory_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ],
   "id": "4dc5fe36c9bc6dd0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:04:07.163840Z",
     "start_time": "2025-02-11T10:04:07.159378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Function to read and process final CSV\n",
    "def process_holt_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads the final CSV and drops the index column if present.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop index column if it exists\n",
    "    if 'index' in df.columns:\n",
    "        df = df.drop('index', axis=1)\n",
    "    elif df.columns[0].lower() in ['unnamed: 0', 'index']:\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "    \n",
    "    return df"
   ],
   "id": "9cb09af2a2bb6a28",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:08:04.472969Z",
     "start_time": "2025-02-11T10:08:04.319020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trump_df = clean_trump_dataset('data/donald_trump/realdonaldtrump.csv')\n",
    "print(\"First dataset shape:\", trump_df.shape)"
   ],
   "id": "3d36b96cac39eba3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dataset shape: (32239, 2)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:05:09.185801Z",
     "start_time": "2025-02-11T10:05:09.143917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bob_ross_df = combine_bob_ross_csv_files('data/bob_ross')\n",
    "print(\"Combined dataset shape:\", bob_ross_df.shape)"
   ],
   "id": "fe748b280b2abcec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (13120, 2)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:05:11.672002Z",
     "start_time": "2025-02-11T10:05:11.666083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "holt_df = process_holt_csv('data/holt/holt.csv')\n",
    "print(\"Final dataset shape:\", holt_df.shape)"
   ],
   "id": "7afe0edd31b3bc23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (577, 2)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:52:28.340518Z",
     "start_time": "2025-02-11T10:52:28.335110Z"
    }
   },
   "cell_type": "code",
   "source": "trump_df.columns",
   "id": "76cbc18c2cecaa6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['content', 'person'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:54:00.673576Z",
     "start_time": "2025-02-11T10:54:00.664574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trump_df = reorder_trump_columns(trump_df)\n",
    "trump_df.columns"
   ],
   "id": "cebd3647d825aa7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:54:07.655688Z",
     "start_time": "2025-02-11T10:54:07.651706Z"
    }
   },
   "cell_type": "code",
   "source": "bob_ross_df.columns",
   "id": "8d5768f7f7ec9941",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:54:08.258084Z",
     "start_time": "2025-02-11T10:54:08.253233Z"
    }
   },
   "cell_type": "code",
   "source": "holt_df.columns",
   "id": "e2cdc20fca9cb53c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:37.660681Z",
     "start_time": "2025-02-11T11:15:37.650410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by:\n",
    "    1. Removing leading/trailing quotation marks\n",
    "    2. Removing @mentions (both with and without spaces)\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to clean\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned text\n",
    "    \"\"\"\n",
    "    # Remove leading and trailing quotation marks\n",
    "    text = text.strip('\"')\n",
    "    \n",
    "    # Remove @mentions:\n",
    "    # 1. Handles \"@someone\"\n",
    "    # 2. Handles \"@ someone\"\n",
    "    text = re.sub(r'@\\s*\\S+\\s?', '', text)\n",
    "    \n",
    "    # Remove any extra whitespace that might have been created\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_trump_text(trump_df):\n",
    "    \"\"\"\n",
    "    Applies text cleaning to Trump's dataset.\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): DataFrame with 'text' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned text\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    cleaned_df = trump_df.copy()\n",
    "    \n",
    "    # Apply cleaning to the text column\n",
    "    cleaned_df['text'] = cleaned_df['text'].apply(clean_text)\n",
    "    \n",
    "    # Print some example transformations\n",
    "    print(\"Sample of transformations (first 3 rows):\")\n",
    "    for old, new in zip(trump_df['text'].head(3), cleaned_df['text'].head(3)):\n",
    "        print(f\"\\nOriginal: {old}\")\n",
    "        print(f\"Cleaned:  {new}\")\n",
    "        \n",
    "    return cleaned_df\n",
    "\n",
    "# Test examples:\n",
    "# print(clean_text('\"@someone is here\"'))  # outputs: \"is here\"\n",
    "# print(clean_text('\"@ someone is here\"'))  # outputs: \"is here\"\n",
    "# print(clean_text('\"\"@ someone is here\"\"'))  # outputs: \"is here\""
   ],
   "id": "7cc14600acf9e370",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:38.732794Z",
     "start_time": "2025-02-11T11:15:38.671928Z"
    }
   },
   "cell_type": "code",
   "source": "trump_df = clean_trump_text(trump_df)",
   "id": "63bac0eda6060cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of transformations (first 3 rows):\n",
      "\n",
      "Original: Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight!\n",
      "Cleaned:  Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight!\n",
      "\n",
      "Original: Donald Trump will be appearing on The View tomorrow morning to discuss Celebrity Apprentice and his new book Think Like A Champion!\n",
      "Cleaned:  Donald Trump will be appearing on The View tomorrow morning to discuss Celebrity Apprentice and his new book Think Like A Champion!\n",
      "\n",
      "Original: \"My persona will never be that of a wallflower - I’d rather build walls than cling to them\" --Donald J. Trump\n",
      "Cleaned:  My persona will never be that of a wallflower - I’d rather build walls than cling to them\" --Donald J. Trump\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:42.328108Z",
     "start_time": "2025-02-11T11:15:42.322109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def balance_datasets(trump_df, bob_ross_df, holt_df):\n",
    "    \"\"\"\n",
    "    Balances all datasets to match the size of the smallest dataset\n",
    "    by random sampling without replacement.\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): Trump dataset\n",
    "        bob_ross_df (pd.DataFrame): Bob Ross dataset\n",
    "        holt_df (pd.DataFrame): Holt dataset\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (balanced_trump_df, balanced_bob_ross_df, balanced_holt_df)\n",
    "    \"\"\"\n",
    "    # Get the sizes of each dataset\n",
    "    sizes = {\n",
    "        'Trump': len(trump_df),\n",
    "        'Bob Ross': len(bob_ross_df),\n",
    "        'Holt': len(holt_df)\n",
    "    }\n",
    "    \n",
    "    # Find the smallest dataset size\n",
    "    min_size = min(sizes.values())\n",
    "    \n",
    "    print(\"Original dataset sizes:\")\n",
    "    for name, size in sizes.items():\n",
    "        print(f\"{name}: {size} rows\")\n",
    "    print(f\"\\nBalancing all datasets to {min_size} rows\")\n",
    "    \n",
    "    # Sample each dataset to the minimum size\n",
    "    balanced_trump = trump_df.sample(n=min_size, random_state=42) if len(trump_df) > min_size else trump_df\n",
    "    balanced_bob_ross = bob_ross_df.sample(n=min_size, random_state=42) if len(bob_ross_df) > min_size else bob_ross_df\n",
    "    balanced_holt = holt_df.sample(n=min_size, random_state=42) if len(holt_df) > min_size else holt_df\n",
    "    \n",
    "    # Verify the balancing\n",
    "    print(\"\\nNew dataset sizes:\")\n",
    "    print(f\"Trump: {len(balanced_trump)} rows\")\n",
    "    print(f\"Bob Ross: {len(balanced_bob_ross)} rows\")\n",
    "    print(f\"Holt: {len(balanced_holt)} rows\")\n",
    "    \n",
    "    return balanced_trump, balanced_bob_ross, balanced_holt"
   ],
   "id": "306b96f417557c48",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:42.692156Z",
     "start_time": "2025-02-11T11:15:42.685924Z"
    }
   },
   "cell_type": "code",
   "source": "balanced_trump, balanced_bob_ross, balanced_holt = balance_datasets(trump_df, bob_ross_df, holt_df)",
   "id": "1b5b02fee3c85fe7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset sizes:\n",
      "Trump: 32239 rows\n",
      "Bob Ross: 13120 rows\n",
      "Holt: 577 rows\n",
      "\n",
      "Balancing all datasets to 577 rows\n",
      "\n",
      "New dataset sizes:\n",
      "Trump: 577 rows\n",
      "Bob Ross: 577 rows\n",
      "Holt: 577 rows\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:43.152145Z",
     "start_time": "2025-02-11T11:15:43.147998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fuse_datasets(trump_df, bob_ross_df, holt_df):\n",
    "    \"\"\"\n",
    "    Combines the three balanced datasets into one shuffled dataset.\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): Balanced Trump dataset\n",
    "        bob_ross_df (pd.DataFrame): Balanced Bob Ross dataset\n",
    "        holt_df (pd.DataFrame): Balanced Holt dataset\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The combined and shuffled dataset\n",
    "    \"\"\"\n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat([trump_df, bob_ross_df, holt_df], ignore_index=True)\n",
    "    \n",
    "    # Shuffle the rows\n",
    "    combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Dataset summary:\")\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "    print(\"\\nRows per person:\")\n",
    "    print(combined_df['person'].value_counts())\n",
    "    \n",
    "    return combined_df"
   ],
   "id": "5f8224ea978ff30",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:43.819458Z",
     "start_time": "2025-02-11T11:15:43.813539Z"
    }
   },
   "cell_type": "code",
   "source": "final_df = fuse_datasets(balanced_trump, balanced_bob_ross, balanced_holt)",
   "id": "5f5b000ff47f0d8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset summary:\n",
      "Total rows: 1731\n",
      "\n",
      "Rows per person:\n",
      "person\n",
      "Bob Ross        577\n",
      "holt            577\n",
      "Donald Trump    577\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:44.257225Z",
     "start_time": "2025-02-11T11:15:44.252751Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.columns",
   "id": "7b55649555b424f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:15:48.269524Z",
     "start_time": "2025-02-11T11:15:48.262716Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.head",
   "id": "98357c5af59ed310",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         person                                               text\n",
       "0     Bob Ross  there we go then with a clean dry 2in brush ve...\n",
       "1         holt  Good idea. Everyone? Gather round, so I can ca...\n",
       "2     Bob Ross  apart from everybody else because you you pay ...\n",
       "3         holt                  Peralta, what are you doing here?\n",
       "4         holt                                     Rub, rub, rub.\n",
       "...        ...                                                ...\n",
       "1726  Bob Ross  And we can go back and get a little white here...\n",
       "1727      holt               I know a way to watch porn in Korea.\n",
       "1728  Bob Ross  If this is gonna be our light source right her...\n",
       "1729      holt  Okay. It's your case. But if anything goes wro...\n",
       "1730  Bob Ross  There sort of pretty, they standout. Now then,...\n",
       "\n",
       "[1731 rows x 2 columns]>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:18:48.964317Z",
     "start_time": "2025-02-11T11:18:48.960164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_remaining_quotes(fused_df):\n",
    "    \"\"\"\n",
    "    Removes any remaining leading and trailing quotation marks from the text column\n",
    "    of the fused dataset.\n",
    "    \n",
    "    Args:\n",
    "        fused_df (pd.DataFrame): Combined dataset with 'text' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned text\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    cleaned_df = fused_df.copy()\n",
    "    \n",
    "    # Strip quotation marks from all texts\n",
    "    cleaned_df['text'] = cleaned_df['text'].str.strip('\"')\n",
    "    \n",
    "    # Print some examples of rows that were changed\n",
    "    mask = fused_df['text'] != cleaned_df['text']\n",
    "    if mask.any():\n",
    "        print(\"\\nSample of rows where quotes were removed:\")\n",
    "        for old, new in zip(fused_df[mask]['text'].head(3), cleaned_df[mask]['text'].head(3)):\n",
    "            print(f\"\\nOriginal: {old}\")\n",
    "            print(f\"Cleaned:  {new}\")\n",
    "    else:\n",
    "        print(\"No quotation marks were found to remove.\")\n",
    "    \n",
    "    return cleaned_df"
   ],
   "id": "894cc2b6f9d07491",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:19:08.499357Z",
     "start_time": "2025-02-11T11:19:08.492900Z"
    }
   },
   "cell_type": "code",
   "source": "final_df = clean_remaining_quotes(final_df)",
   "id": "8a8d090c8d7ab477",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of rows where quotes were removed:\n",
      "\n",
      "Original: Hmm. I'm surprised she hasn't marched in here to say \"I told you so.\"\n",
      "Cleaned:  Hmm. I'm surprised she hasn't marched in here to say \"I told you so.\n",
      "\n",
      "Original: \" Ugandan mogul Ashish Thakkar says that Donald Trump is ignorant about Africa\" Wrong, if anything it's worse than I say\n",
      "Cleaned:   Ugandan mogul Ashish Thakkar says that Donald Trump is ignorant about Africa\" Wrong, if anything it's worse than I say\n",
      "\n",
      "Original: Well, it says here it's scheduled \"after everyone leaves.\"\n",
      "Cleaned:  Well, it says here it's scheduled \"after everyone leaves.\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:19:12.765712Z",
     "start_time": "2025-02-11T11:19:12.756714Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.to_csv('data/final_fused_data.csv', index=False)\n",
   "id": "19be0596ebf37230",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "13e186d31ef011c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
