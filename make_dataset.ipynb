{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T12:40:53.617321Z",
     "start_time": "2025-02-13T12:40:53.309126Z"
    }
   },
   "source": [
    "# Cell 1: Import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:40:55.628440Z",
     "start_time": "2025-02-13T12:40:55.623674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 1: Import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def clean_trump_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Reads Donald Trump's CSV, removes rows with links and pic.twitter,\n",
    "    keeps only one column, and adds a 'person' column.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Trump CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove rows containing links or pic.twitter\n",
    "    mask = ~(\n",
    "        df['content'].str.contains('http://|https://|pic\\.twitter', \n",
    "                                 regex=True, \n",
    "                                 na=False)\n",
    "    )\n",
    "    df = df[mask]\n",
    "    \n",
    "    # Keep only the 'content' column and add 'person' column\n",
    "    df = df[['content']].copy()\n",
    "    df['person'] = 'Donald Trump'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reorder_trump_columns(trump_df):\n",
    "    \"\"\"\n",
    "    Renames 'content' to 'text' and reorders columns to [person, text]\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): DataFrame with [content, person] columns\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with renamed and reordered columns [person, text]\n",
    "    \"\"\"\n",
    "    # Rename content to text\n",
    "    trump_df = trump_df.rename(columns={'content': 'text'})\n",
    "    \n",
    "    # Reorder columns\n",
    "    trump_df = trump_df[['person', 'text']]\n",
    "    \n",
    "    return trump_df"
   ],
   "id": "b203cfc5db764782",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:40:56.969238Z",
     "start_time": "2025-02-13T12:40:56.964999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Function to process directory of CSVs\n",
    "def combine_bob_ross_csv_files(directory_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a directory into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to directory containing CSV files\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame\n",
    "    \"\"\"\n",
    "    # List to store individual DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Iterate through all CSV files in the directory\n",
    "    for file in os.listdir(directory_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ],
   "id": "4dc5fe36c9bc6dd0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:40:57.642738Z",
     "start_time": "2025-02-13T12:40:57.636905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Function to read and process final CSV\n",
    "def process_holt_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads the final CSV and drops the index column if present.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop index column if it exists\n",
    "    if 'index' in df.columns:\n",
    "        df = df.drop('index', axis=1)\n",
    "    elif df.columns[0].lower() in ['unnamed: 0', 'index']:\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "    \n",
    "    return df"
   ],
   "id": "9cb09af2a2bb6a28",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:40:59.322703Z",
     "start_time": "2025-02-13T12:40:59.153979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trump_df = clean_trump_dataset('data/donald_trump/realdonaldtrump.csv')\n",
    "print(\"First dataset shape:\", trump_df.shape)"
   ],
   "id": "3d36b96cac39eba3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dataset shape: (32239, 2)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:00.099709Z",
     "start_time": "2025-02-13T12:41:00.051279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bob_ross_df = combine_bob_ross_csv_files('data/bob_ross')\n",
    "print(\"Combined dataset shape:\", bob_ross_df.shape)"
   ],
   "id": "fe748b280b2abcec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (13120, 2)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:02.152302Z",
     "start_time": "2025-02-13T12:41:02.143869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "holt_df = process_holt_csv('data/holt/holt.csv')\n",
    "print(\"Final dataset shape:\", holt_df.shape)"
   ],
   "id": "7afe0edd31b3bc23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (577, 2)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:03.370683Z",
     "start_time": "2025-02-13T12:41:03.363679Z"
    }
   },
   "cell_type": "code",
   "source": "trump_df.columns",
   "id": "76cbc18c2cecaa6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['content', 'person'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:04.399691Z",
     "start_time": "2025-02-13T12:41:04.385887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trump_df = reorder_trump_columns(trump_df)\n",
    "trump_df.columns"
   ],
   "id": "cebd3647d825aa7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:04.853855Z",
     "start_time": "2025-02-13T12:41:04.848760Z"
    }
   },
   "cell_type": "code",
   "source": "bob_ross_df.columns",
   "id": "8d5768f7f7ec9941",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:05.279060Z",
     "start_time": "2025-02-13T12:41:05.273662Z"
    }
   },
   "cell_type": "code",
   "source": "holt_df.columns",
   "id": "e2cdc20fca9cb53c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:05.763854Z",
     "start_time": "2025-02-13T12:41:05.755333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by:\n",
    "    1. Removing leading/trailing quotation marks\n",
    "    2. Removing @mentions (both with and without spaces)\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to clean\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned text\n",
    "    \"\"\"\n",
    "    # Remove leading and trailing quotation marks\n",
    "    text = text.strip('\"')\n",
    "    \n",
    "    # Remove @mentions:\n",
    "    # 1. Handles \"@someone\"\n",
    "    # 2. Handles \"@ someone\"\n",
    "    text = re.sub(r'@\\s*\\S+\\s?', '', text)\n",
    "    \n",
    "    # Remove any extra whitespace that might have been created\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_trump_text(trump_df):\n",
    "    \"\"\"\n",
    "    Applies text cleaning to Trump's dataset.\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): DataFrame with 'text' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned text\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    cleaned_df = trump_df.copy()\n",
    "    \n",
    "    # Apply cleaning to the text column\n",
    "    cleaned_df['text'] = cleaned_df['text'].apply(clean_text)\n",
    "    \n",
    "    # Print some example transformations\n",
    "    print(\"Sample of transformations (first 3 rows):\")\n",
    "    for old, new in zip(trump_df['text'].head(3), cleaned_df['text'].head(3)):\n",
    "        print(f\"\\nOriginal: {old}\")\n",
    "        print(f\"Cleaned:  {new}\")\n",
    "        \n",
    "    return cleaned_df\n",
    "\n",
    "# Test examples:\n",
    "# print(clean_text('\"@someone is here\"'))  # outputs: \"is here\"\n",
    "# print(clean_text('\"@ someone is here\"'))  # outputs: \"is here\"\n",
    "# print(clean_text('\"\"@ someone is here\"\"'))  # outputs: \"is here\""
   ],
   "id": "7cc14600acf9e370",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:41:07.536266Z",
     "start_time": "2025-02-13T12:41:07.466744Z"
    }
   },
   "cell_type": "code",
   "source": "trump_df = clean_trump_text(trump_df)",
   "id": "63bac0eda6060cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of transformations (first 3 rows):\n",
      "\n",
      "Original: Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight!\n",
      "Cleaned:  Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight!\n",
      "\n",
      "Original: Donald Trump will be appearing on The View tomorrow morning to discuss Celebrity Apprentice and his new book Think Like A Champion!\n",
      "Cleaned:  Donald Trump will be appearing on The View tomorrow morning to discuss Celebrity Apprentice and his new book Think Like A Champion!\n",
      "\n",
      "Original: \"My persona will never be that of a wallflower - I’d rather build walls than cling to them\" --Donald J. Trump\n",
      "Cleaned:  My persona will never be that of a wallflower - I’d rather build walls than cling to them\" --Donald J. Trump\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:42:59.816554Z",
     "start_time": "2025-02-13T12:42:59.810517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def balance_datasets(trump_df, bob_ross_df, holt_df):\n",
    "    \"\"\"\n",
    "    Balances all datasets to match the size of the smallest dataset\n",
    "    by random sampling without replacement.\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): Trump dataset\n",
    "        bob_ross_df (pd.DataFrame): Bob Ross dataset\n",
    "        holt_df (pd.DataFrame): Holt dataset\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (balanced_trump_df, balanced_bob_ross_df, balanced_holt_df)\n",
    "    \"\"\"\n",
    "    # Get the sizes of each dataset\n",
    "    sizes = {\n",
    "        'Trump': len(trump_df),\n",
    "        'Bob Ross': len(bob_ross_df),\n",
    "        #'Holt': len(holt_df)\n",
    "    }\n",
    "    \n",
    "    # Find the smallest dataset size\n",
    "    \n",
    "    #if you want the size of the min dataset\n",
    "    #min_size = min(sizes.values())\n",
    "    \n",
    "    #if you want to define the size yourself\n",
    "    min_size = 2000\n",
    "    \n",
    "    print(\"Original dataset sizes:\")\n",
    "    for name, size in sizes.items():\n",
    "        print(f\"{name}: {size} rows\")\n",
    "    print(f\"\\nBalancing all datasets to {min_size} rows\")\n",
    "    \n",
    "    # Sample each dataset to the minimum size\n",
    "    balanced_trump = trump_df.sample(n=min_size, random_state=42) if len(trump_df) > min_size else trump_df\n",
    "    balanced_bob_ross = bob_ross_df.sample(n=min_size, random_state=42) if len(bob_ross_df) > min_size else bob_ross_df\n",
    "    #balanced_holt = holt_df.sample(n=min_size, random_state=42) if len(holt_df) > min_size else holt_df\n",
    "    \n",
    "    # Verify the balancing\n",
    "    print(\"\\nNew dataset sizes:\")\n",
    "    print(f\"Trump: {len(balanced_trump)} rows\")\n",
    "    print(f\"Bob Ross: {len(balanced_bob_ross)} rows\")\n",
    "    #print(f\"Holt: {len(balanced_holt)} rows\")\n",
    "    \n",
    "    return balanced_trump, balanced_bob_ross, #balanced_holt"
   ],
   "id": "306b96f417557c48",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:43:00.567382Z",
     "start_time": "2025-02-13T12:43:00.561213Z"
    }
   },
   "cell_type": "code",
   "source": "balanced_trump, balanced_bob_ross = balance_datasets(trump_df, bob_ross_df, holt_df)",
   "id": "1b5b02fee3c85fe7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset sizes:\n",
      "Trump: 32239 rows\n",
      "Bob Ross: 13120 rows\n",
      "\n",
      "Balancing all datasets to 2000 rows\n",
      "\n",
      "New dataset sizes:\n",
      "Trump: 2000 rows\n",
      "Bob Ross: 2000 rows\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:44:32.365614Z",
     "start_time": "2025-02-13T12:44:32.360610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def fuse_datasets(trump_df, bob_ross_df, holt_df):\n",
    "def fuse_datasets(trump_df, bob_ross_df):\n",
    "    \"\"\"\n",
    "    Combines the three balanced datasets into one shuffled dataset.\n",
    "    \n",
    "    Args:\n",
    "        trump_df (pd.DataFrame): Balanced Trump dataset\n",
    "        bob_ross_df (pd.DataFrame): Balanced Bob Ross dataset\n",
    "        holt_df (pd.DataFrame): Balanced Holt dataset\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The combined and shuffled dataset\n",
    "    \"\"\"\n",
    "    # Combine all dataframes\n",
    "    # combined_df = pd.concat([trump_df, bob_ross_df, holt_df], ignore_index=True)\n",
    "    combined_df = pd.concat([trump_df, bob_ross_df], ignore_index=True)\n",
    "    # Shuffle the rows\n",
    "    \n",
    "    combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Dataset summary:\")\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "    print(\"\\nRows per person:\")\n",
    "    print(combined_df['person'].value_counts())\n",
    "    \n",
    "    return combined_df"
   ],
   "id": "5f8224ea978ff30",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:44:32.871228Z",
     "start_time": "2025-02-13T12:44:32.865293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# final_df = fuse_datasets(balanced_trump, balanced_bob_ross, balanced_holt)\n",
    "final_df = fuse_datasets(balanced_trump, balanced_bob_ross)"
   ],
   "id": "5f5b000ff47f0d8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset summary:\n",
      "Total rows: 4000\n",
      "\n",
      "Rows per person:\n",
      "person\n",
      "Donald Trump    2000\n",
      "Bob Ross        2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:44:35.960866Z",
     "start_time": "2025-02-13T12:44:35.955612Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.columns",
   "id": "7b55649555b424f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'text'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:44:38.419590Z",
     "start_time": "2025-02-13T12:44:38.413479Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.head",
   "id": "98357c5af59ed310",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             person                                               text\n",
       "0     Donald Trump  It’s time for to enter All time hits leader ha...\n",
       "1         Bob Ross  Now I like taking the liner brush. Once again ...\n",
       "2     Donald Trump               Donald Trump on he'll be at tomorrow\n",
       "3         Bob Ross       Were getting much darker in color now. There\n",
       "4         Bob Ross  Thin the paint, very, very thin, and then you ...\n",
       "...            ...                                                ...\n",
       "3995  Donald Trump  Reuters just announced that Secret Service nev...\n",
       "3996  Donald Trump  I can't wait for to announce that he's running...\n",
       "3997  Donald Trump                                 Which they should!\n",
       "3998      Bob Ross  were doing is tapping just tapping following t...\n",
       "3999      Bob Ross  Weve covered the entire surface with a thin, e...\n",
       "\n",
       "[4000 rows x 2 columns]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:44:44.450593Z",
     "start_time": "2025-02-13T12:44:44.440197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_remaining_quotes(fused_df):\n",
    "    \"\"\"\n",
    "    Removes any remaining leading and trailing quotation marks from the text column\n",
    "    of the fused dataset.\n",
    "    \n",
    "    Args:\n",
    "        fused_df (pd.DataFrame): Combined dataset with 'text' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned text\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    cleaned_df = fused_df.copy()\n",
    "    \n",
    "    # Strip quotation marks from all texts\n",
    "    cleaned_df['text'] = cleaned_df['text'].str.strip('\"')\n",
    "    \n",
    "    # Print some examples of rows that were changed\n",
    "    mask = fused_df['text'] != cleaned_df['text']\n",
    "    if mask.any():\n",
    "        print(\"\\nSample of rows where quotes were removed:\")\n",
    "        for old, new in zip(fused_df[mask]['text'].head(3), cleaned_df[mask]['text'].head(3)):\n",
    "            print(f\"\\nOriginal: {old}\")\n",
    "            print(f\"Cleaned:  {new}\")\n",
    "    else:\n",
    "        print(\"No quotation marks were found to remove.\")\n",
    "    \n",
    "    return cleaned_df"
   ],
   "id": "894cc2b6f9d07491",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:44:46.079179Z",
     "start_time": "2025-02-13T12:44:46.072179Z"
    }
   },
   "cell_type": "code",
   "source": "final_df = clean_remaining_quotes(final_df)",
   "id": "8a8d090c8d7ab477",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of rows where quotes were removed:\n",
      "\n",
      "Original: \"Sometimes by losing a battle you find a new way to win the war.\" - Donald Trump # Inspirational\n",
      "Cleaned:  Sometimes by losing a battle you find a new way to win the war.\" - Donald Trump # Inspirational\n",
      "\n",
      "Original: \"I wish I could go on Jay's show so badly!\" Real quote from Real quote is \"I wish they would stop calling\n",
      "Cleaned:  I wish I could go on Jay's show so badly!\" Real quote from Real quote is \"I wish they would stop calling\n",
      "\n",
      "Original: \"that's because you've never hired anyone to do work before\" favorite line from tonights debate.\n",
      "Cleaned:  that's because you've never hired anyone to do work before\" favorite line from tonights debate.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:45:05.386252Z",
     "start_time": "2025-02-13T12:45:05.368560Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.to_csv('data/just_trump_and_ross_2000_each.csv', index=False)\n",
   "id": "19be0596ebf37230",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "13e186d31ef011c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
